import numpy as np
from scipy.stats import mode
from sklearn.cross_validation import train_test_split
from scipy.spatial.distance import euclidean as euc_dis
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
import pandas as pd


class Dataset:
    def __init__(self, csv, test_size, random_state):
        self.ds = pd.read_csv(csv, header=None)
        ds_column_len = len(self.ds.columns)
        self.convert_nominal_data()
        self.data = self.ds.loc[:, : ds_column_len - 2]
        self.targets = self.ds[ds_column_len - 1]
        print("ds_column_len: ", ds_column_len)
        print("datads: \n", self.data)
        print("targetsds: \n", self.targets)
        self.data_train = []
        self.data_test = []
        self.target_train = []
        self.target_test = []
        self.std_train = []
        self.std_test = []

        self.data_train, self.data_test, self.target_train, self.target_test = train_test_split(
                self.data, self.targets, test_size=test_size, random_state=random_state)
        self.std_train = [0] * int(len(self.data_train))
        self.std_test = [0] * int(len(self.data_test))

        self.standardize_data()

    def convert_nominal_data(self):
        le = preprocessing.LabelEncoder()
        num_col = len(self.ds.columns)

        for i in range(0, num_col):
            has_string = False
            le.fit(self.ds[i])
            list_of_classes = list(le.classes_)
            for a_class in list_of_classes:
                if isinstance(a_class, str):
                    has_string = True
            if has_string:
                self.ds[i] = le.transform(self.ds[i])

    def standardize_data(self):
        # fill std_train with standardized values
        self.std_train = (self.data_train - self.data_train.mean()) / self.data_train.std()
        # fill std_test with standardized values
        self.std_test = (self.data_test - self.data_train.mean()) / self.data_train.std()


class KNN:
    def __init__(self, k, data, targets, inputs):
        self.k = k
        self.data = data
        self.targets = targets
        self.inputs = inputs
        self.nInputs = np.shape(inputs)[0]
        self.closest = np.zeros(self.nInputs)
        print("NUM INPUTS:\n ", self.nInputs)


    def find_distances(self, input):
        # euclidian distance for each training vector from the current input n

        # initialize distances to the length of data
        self.distances = [0] * int(len(self.data))

        # for each data vector, compare it to the current i and add it to the distances formula
        for j in range(len(self.data)):
            self.distances[j] = euc_dis(self.data.iloc[j], input)

    def knn(self):

        for i in range(self.nInputs):

            print("********Iteration*********** #", i)
            self.find_distances(self.inputs.iloc[i])

            # sorts an array but keeps indexes the same
            indices = np.argsort(self.distances, axis=0)

            self.possible_classes = []
            self.closest_classes = []
            self.counter_classes = []
            self.most_common_class = []
            for n in range(0, self.k):
                self.closest_classes.insert(n, self.targets.iloc[indices[n]])
            self.possible_classes = np.unique(self.closest_classes)
            print("closest classes: ", self.closest_classes)
            # print("possible classes: ", self.possible_classes)

            if self.k == 1:
                self.closest[i] = np.unique(self.possible_classes)
            else:
                self.closest[i] = mode(self.closest_classes)[0][0]
                print("insert: ", self.closest[i])
        return self.closest


print("**********************CSV**************************26")

my_dataset = Dataset('cars', .3, 3333)

nearestneighbor = KNN(1, my_dataset.std_train, my_dataset.target_train, my_dataset.std_test)

closest = nearestneighbor.knn()

closest = closest.astype(int)

print("closest: ", closest)

acc_score = accuracy_score(my_dataset.target_test, closest)

print("Accuracy of .knn() is: ", acc_score)


# cars with 3
# closest:  [2 2 0 0 2 2 2 0 2 2 2 0 0 0 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 0 0 2 0 2 0 2 3
#  0 0 2 0 2 0 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2
#  2 2 0 2 2 2 2 0 2 2 0 2 2 0 2 0 2 2 3 2 2 2 0 2 2 0 2 0 2 2 2 0 2 2 2 2 2
#  0 0 1 2 2 0 2 0 0 2 3 0 2 2 2 2 0 2 0 0 2 2 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2
#  2 2 0 2 2 0 0 0 2 2 0 2 2 2 2 1 2 0 0 2 2 1 1 2 0 2 2 0 2 2 2 2 2 2 2 0 2
#  2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 0 3 2
#  2 2 2 3 2 0 2 2 2 3 2 0 2 2 0 0 2 2 2 0 0 2 2 2 2 0 0 2 2 2 2 0 2 0 2 2 0
#  2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 0 2 2 2 2 0 2 2 1 2 0 2 2 2
#  2 0 2 2 2 2 2 3 2 2 2 2 2 2 0 2 2 0 0 0 2 2 2 2 2 2 0 0 2 0 0 2 2 2 2 2 2
#  2 0 2 2 3 0 2 0 2 0 2 3 2 2 2 2 2 0 2 2 2 2 2 2 2 1 2 2 2 2 2 2 0 2 0 2 2
#  2 0 2 2 0 2 0 2 2 2 2 2 2 0 0 2 2 2 2 0 2 0 0 2 0 3 2 2 2 0 2 2 2 0 2 2 0
#  2 2 2 2 2 2 0 0 2 0 0 0 0 0 0 2 2 2 1 2 2 2 2 2 2 3 2 1 3 0 2 2 0 2 2 2 2
#  0 2 2 0 3 2 2 1 2 0 2 2 2 2 2 0 0 2 2 2 2 0 0 2 2 2 2 0 2 3 2 2 2 2 1 2 0
#  2 2 2 2 0 2 2 2 0 2 0 2 0 2 2 2 0 2 2 2 1 2 0 3 2 2 0 0 2 0 2 0 2 2 2 2 0
#  0]
# Accuracy of .knn() is:  0.926782273603

# iris with 1
# closest:  [1 2 2 2 1 1 0 0 2 2 2 2 1 2 0 2 2 0 0 0 1 1 1 2 1 2 0 2 1 0 0 2 2 0 1 1 1
#  2 2 0 1 1 1 1 1]
# Accuracy of .knn() is:  0.933333333333
